
from datetime import date, timedelta
from typing import List, Dict, Any

import httpx
import re
from sqlalchemy.orm import Session

from backend.app.config import settings
from backend.app.db.models import NewsDaily
from backend.app.utils.filters import is_breaking_news

NAVER_NEWS_URL = "https://openapi.naver.com/v1/search/news.json"


def _ensure_naver_credentials() -> None:
    if not settings.NAVER_CLIENT_ID or not settings.NAVER_CLIENT_SECRET:
        raise RuntimeError("NAVER_CLIENT_ID / NAVER_CLIENT_SECRET not set in environment")


def build_topic_key(title: str) -> str:
    """ì œëª©ì—ì„œ íƒœê·¸/íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ê³  ì¤‘ë³µ íŒë³„ìš© í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not title:
        return ""

    cleaned = title
    cleaned = cleaned.replace("<b>", "").replace("</b>", "")
    cleaned = cleaned.replace("[ì†ë³´]", "").replace("[ë‹¨ë…]", "")
    cleaned = re.sub(r"[^0-9ê°€-í£a-zA-Z ]", "", cleaned)
    cleaned = cleaned.replace(" ", "").lower()
    return cleaned[:60]


def fetch_naver_news_raw(
    query: str,
    display: int = 50,
    sort: str = "date",
) -> List[Dict[str, Any]]:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIì—ì„œ raw item ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    _ensure_naver_credentials()

    headers = {
        "X-Naver-Client-Id": settings.NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": settings.NAVER_CLIENT_SECRET,
    }
    params = {
        "query": query,
        "display": display,
        "sort": sort,
    }

    with httpx.Client(timeout=10.0) as client:
        resp = client.get(NAVER_NEWS_URL, headers=headers, params=params)
        resp.raise_for_status()
        data = resp.json()

    return data.get("items", [])


def save_news_items(
    db: Session,
    items: List[Dict[str, Any]],
    *,
    category: str,
) -> List[NewsDaily]:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ item ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì¤‘ë³µ ì œê±° í›„ DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    today = date.today()
    three_days_ago = today - timedelta(days=3)  # ìµœê·¼ 3ì¼
    created: List[NewsDaily] = []
    
    # ë””ë²„ê¹… ì¹´ìš´í„°
    total_count = len(items)
    blocked_by_press = 0
    blocked_by_keyword = 0
    blocked_by_duplicate = 0
    
    print(f"\nâ”â”â” [{category}] ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ â”â”â”")
    print(f"ğŸ“¥ ë„¤ì´ë²„ì—ì„œ ë°›ì€ ë‰´ìŠ¤: {total_count}ê°œ")

    for item in items:
        raw_title = item.get("title") or ""
        title = raw_title.replace("<b>", "").replace("</b>", "")
        topic_key = build_topic_key(title)

        if not topic_key:
            continue
        
        # pubDate ì²´í¬ - 3ì¼ ì´ë‚´ ë‰´ìŠ¤ë§Œ ì €ì¥
        pub_date_str = item.get("pubDate")
        if pub_date_str:
            try:
                from datetime import datetime
                from email.utils import parsedate_to_datetime
                pub_date = parsedate_to_datetime(pub_date_str)
                pub_date_only = pub_date.date()
                
                # 3ì¼ ì´ìƒ ëœ ë‰´ìŠ¤ëŠ” ì°¨ë‹¨
                if (today - pub_date_only).days > 3:
                    continue
            except Exception:
                pass  # pubDate íŒŒì‹± ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ í†µê³¼

        # ìµœê·¼ 3ì¼ ì´ë‚´ ê°™ì€ ë‰´ìŠ¤ê°€ ìˆëŠ”ì§€ ì²´í¬ (ì§€ë‚œ ì¼ì€ ì§€ë‚œ ì¼)
        existing = (
            db.query(NewsDaily)
            .filter(
                NewsDaily.date >= three_days_ago,
                NewsDaily.topic_key == topic_key
            )
            .first()
        )
        if existing:
            blocked_by_duplicate += 1
            continue

        source = (item.get("originallink") or item.get("link") or "")[:100]
        url = item.get("originallink") or item.get("link") or ""
        
        # pubDate íŒŒì‹± - ì‹¤ì œ ë°œí–‰ì¼ í™•ì¸
        pub_date_str = item.get("pubDate")
        news_date = today  # ê¸°ë³¸ê°’ì€ ì˜¤ëŠ˜
        
        if pub_date_str:
            try:
                from datetime import datetime
                from email.utils import parsedate_to_datetime
                pub_datetime = parsedate_to_datetime(pub_date_str)
                news_date = pub_datetime.date()
                
                # 2ì¼ ì´ìƒ ëœ ë‰´ìŠ¤ëŠ” ì°¨ë‹¨
                days_old = (today - news_date).days
                if days_old > 2:
                    continue
            except Exception:
                # íŒŒì‹± ì‹¤íŒ¨í•˜ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì €ì¥
                news_date = today

        # ì–¸ë¡ ì‚¬ í•„í„°: í—ˆìš©ëœ ì–¸ë¡ ì‚¬ê°€ ì•„ë‹ˆë©´ ì €ì¥ ì•ˆ í•¨
        from backend.app.utils.filters import extract_press_from_url, PRESS_BREAKING_CONFIG, EXCLUDE_KEYWORDS
        
        press = extract_press_from_url(url)
        
        # 1. í—ˆìš©ëœ ì–¸ë¡ ì‚¬ê°€ ì•„ë‹ˆë©´ ì°¨ë‹¨
        if not press or press not in PRESS_BREAKING_CONFIG:
            blocked_by_press += 1
            # ì²˜ìŒ 5ê°œë§Œ ë¡œê·¸
            if blocked_by_press <= 5:
                print(f"  âŒ [{press or 'ì•Œìˆ˜ì—†ìŒ'}] {title[:30]}...")
            continue
        
        # 2. ì œì™¸ í‚¤ì›Œë“œ ìˆìœ¼ë©´ ì°¨ë‹¨
        should_exclude = False
        for keyword in EXCLUDE_KEYWORDS:
            if keyword in title:
                should_exclude = True
                break
        if should_exclude:
            blocked_by_keyword += 1
            continue

        # 3. pubDate íŒŒì‹± - ì˜¤ëŠ˜ ë‰´ìŠ¤ë§Œ
        pub_date_str = item.get("pubDate")
        news_date = today  # ê¸°ë³¸ê°’
        
        if pub_date_str:
            try:
                from datetime import datetime
                from email.utils import parsedate_to_datetime
                pub_dt = parsedate_to_datetime(pub_date_str)
                pub_date_only = pub_dt.date()
                
                # ì˜¤ëŠ˜ì´ ì•„ë‹ˆë©´ ì°¨ë‹¨
                if pub_date_only != today:
                    continue
                
                news_date = pub_date_only  # ì‹¤ì œ ë°œí–‰ì¼
            except:
                pass  # íŒŒì‹± ì‹¤íŒ¨í•˜ë©´ ì˜¤ëŠ˜ë¡œ
        
        # 4. ì†ë³´ íŒ¨í„´ ì²´í¬ (is_breaking í”Œë˜ê·¸ìš©)
        is_breaking = is_breaking_news(title, url, category)
        
        print(f"  âœ… [{press}] {title[:40]}...")

        news = NewsDaily(
            date=news_date,  # ì‹¤ì œ ë°œí–‰ì¼ë¡œ ì €ì¥
            source=source,
            title=title,
            url=url,
            category=category,
            is_top=False,
            is_breaking=is_breaking,
            topic_key=topic_key,
            keywords=None,
            sentiment=None,
        )
        db.add(news)
        created.append(news)

    db.commit()
    for n in created:
        db.refresh(n)
    
    print(f"\nğŸ“Š ê²°ê³¼:")
    print(f"  - ë„¤ì´ë²„ì—ì„œ ë°›ìŒ: {total_count}ê°œ")
    print(f"  - ì–¸ë¡ ì‚¬ í•„í„° ì°¨ë‹¨: {blocked_by_press}ê°œ")
    print(f"  - í‚¤ì›Œë“œ í•„í„° ì°¨ë‹¨: {blocked_by_keyword}ê°œ")
    print(f"  - ì¤‘ë³µ ì°¨ë‹¨: {blocked_by_duplicate}ê°œ")
    print(f"  - âœ… ì €ì¥ë¨: {len(created)}ê°œ\n")

    return created


def build_daily_top5(db: Session) -> Dict[str, List[NewsDaily]]:
    """ì˜¤ëŠ˜ ê¸°ì¤€ 4ê°œ ì¹´í…Œê³ ë¦¬(ì‚¬íšŒ/ê²½ì œ/ë¬¸í™”/ì—°ì˜ˆ) Top5ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
    today = date.today()

    # ë§¤ë²ˆ ì˜¤ëŠ˜ ë‰´ìŠ¤ ì „ì²´ ì‚­ì œ (ìµœì‹  ë‰´ìŠ¤ë¡œ ê°±ì‹ )
    db.query(NewsDaily).filter(NewsDaily.date == today).delete()
    db.commit()

    # ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ (100ê°œì”©)
    society_items = fetch_naver_news_raw(query="ì‚¬íšŒ ë‰´ìŠ¤", display=100, sort="date")
    economy_items = fetch_naver_news_raw(query="ê²½ì œ ë‰´ìŠ¤", display=100, sort="date")
    culture_items = fetch_naver_news_raw(query="ë¬¸í™” ë‰´ìŠ¤", display=100, sort="date")
    entertainment_items = fetch_naver_news_raw(query="ì—°ì˜ˆ ë‰´ìŠ¤", display=100, sort="date")

    # DBì— ì €ì¥
    save_news_items(db, society_items, category="society")
    save_news_items(db, economy_items, category="economy")
    save_news_items(db, culture_items, category="culture")
    save_news_items(db, entertainment_items, category="entertainment")

    # ê¸°ì¡´ Top5 í”Œë˜ê·¸ ì´ˆê¸°í™”
    for cat in ("society", "economy", "culture", "entertainment"):
        (
            db.query(NewsDaily)
            .filter(NewsDaily.date == today, NewsDaily.category == cat, NewsDaily.is_top.is_(True))
            .update({NewsDaily.is_top: False})
        )
    db.commit()

    result: Dict[str, List[NewsDaily]] = {}

    # ê° ì¹´í…Œê³ ë¦¬ë³„ Top5 ì„ ì •
    for cat in ("society", "economy", "culture", "entertainment"):
        top_list: List[NewsDaily] = (
            db.query(NewsDaily)
            .filter(NewsDaily.date == today, NewsDaily.category == cat)
            .order_by(NewsDaily.created_at.desc())
            .limit(5)
            .all()
        )
        for news in top_list:
            news.is_top = True
        db.commit()
        result[cat] = top_list

    return result


def collect_breaking_news(db: Session) -> List[NewsDaily]:
    """ì†ë³´ ê¸°ì‚¬ ìˆ˜ì§‘ ë° ìƒˆë¡œ ì¶”ê°€ëœ ì†ë³´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    items = fetch_naver_news_raw(query="ì†ë³´", display=20, sort="date")
    created = save_news_items(db, items, category="breaking")
    return created
