"""
Morning Bot v3.0 - ì–¸ë¡ ì‚¬ë³„ ìˆ˜ì§‘ + í•« ì ìˆ˜ ì‹œìŠ¤í…œ
"""

from datetime import date, datetime, timedelta
from typing import List, Dict, Any
from sqlalchemy import func
from sqlalchemy.orm import Session
from sqlalchemy.exc import IntegrityError

import httpx
import re

from backend.app.config import settings
from backend.app.db.models import NewsDaily
from backend.app.utils.filters import extract_press_from_url, PRESS_BREAKING_CONFIG
from backend.app.utils.category_keywords import classify_category

NAVER_NEWS_URL = "https://openapi.naver.com/v1/search/news.json"

# 20ê°œ ì–¸ë¡ ì‚¬
PRESS_LIST = [
    "ë§¤ì¼ê²½ì œ", "í•œêµ­ê²½ì œ", "ë¨¸ë‹ˆíˆ¬ë°ì´", "ì„œìš¸ê²½ì œ", "í—¤ëŸ´ë“œê²½ì œ",
    "ì•„ì‹œì•„ê²½ì œ", "ì´ë°ì¼ë¦¬", "ì¡°ì„ ë¹„ì¦ˆ", "íŒŒì´ë‚¸ì…œë‰´ìŠ¤",
    "ì—°í•©ë‰´ìŠ¤", "YTN", "KBS", "SBS", "JTBC",
    "êµ­ë¯¼ì¼ë³´", "ì½”ë¦¬ì•„í—¤ëŸ´ë“œ", "ì•„ì´ë‰´ìŠ¤24", "ë””ì§€í„¸íƒ€ì„ìŠ¤", "í•œê²¨ë ˆ", "SBS"
]


def build_topic_key(title: str) -> str:
    """ì¤‘ë³µ íŒë³„ìš© í‚¤ ìƒì„± (30ìë¡œ ë‹¨ì¶•)"""
    if not title:
        return ""
    
    cleaned = title
    cleaned = cleaned.replace("<b>", "").replace("</b>", "")
    cleaned = cleaned.replace("[ì†ë³´]", "").replace("[ë‹¨ë…]", "").replace("[ê¸´ê¸‰]", "")
    cleaned = re.sub(r"[^0-9ê°€-í£a-zA-Z ]", "", cleaned)
    cleaned = cleaned.replace(" ", "").lower()
    return cleaned[:30]


def check_breaking_tag(title: str) -> bool:
    """ì†ë³´ íƒœê·¸ í™•ì¸"""
    breaking_patterns = ["[ì†ë³´]", "[ê¸´ê¸‰]", "[ë‹¨ë…]", "ì†ë³´:", "ë‹¨ë…:"]
    for pattern in breaking_patterns:
        if pattern in title:
            return True
    return False


def fetch_naver_news_raw(query: str, display: int = 100) -> List[Dict[str, Any]]:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ"""
    
    if not settings.NAVER_CLIENT_ID or not settings.NAVER_CLIENT_SECRET:
        raise RuntimeError("NAVER credentials not set")
    
    headers = {
        "X-Naver-Client-Id": settings.NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": settings.NAVER_CLIENT_SECRET,
    }
    params = {
        "query": query,
        "display": display,
        "sort": "date",
    }
    
    try:
        resp = httpx.get(NAVER_NEWS_URL, params=params, headers=headers, timeout=10.0)
        resp.raise_for_status()
        return resp.json().get("items", [])
    except Exception as e:
        print(f"  âŒ API ì˜¤ë¥˜: {e}")
        return []


def collect_by_press(db: Session) -> List[NewsDaily]:
    """ì–¸ë¡ ì‚¬ë³„ ìˆ˜ì§‘ (20ê°œ Ã— 100ê°œ = 2,000ê°œ)"""
    
    from backend.app.utils.dedup import remove_duplicate_news
    
    today = date.today()
    created = []
    temp_news_list = []  # ì¤‘ë³µ ì œê±° ì „ ì„ì‹œ ë¦¬ìŠ¤íŠ¸
    
    print(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"ğŸ“° ì–¸ë¡ ì‚¬ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    total_fetched = 0
    total_saved = 0
    
    for press in PRESS_LIST:
        print(f"\nğŸ” [{press}] ìˆ˜ì§‘ ì¤‘...")
        
        items = fetch_naver_news_raw(query=press, display=100)
        total_fetched += len(items)
        
        if not items:
            print(f"  âš ï¸ ê²°ê³¼ ì—†ìŒ")
            continue
        
        saved_count = 0
        
        for item in items:
            try:
                # 1. í•„ìˆ˜ í•„ë“œ ê²€ì¦
                raw_title = item.get("title")
                url = item.get("originallink") or item.get("link")
                
                if not raw_title or not url:
                    continue
                
                # 2. ì œëª© ì •ì œ
                title = raw_title.replace("<b>", "").replace("</b>", "")
                topic_key = build_topic_key(title)
                
                if not topic_key:
                    continue
                
                # 3. ì¤‘ë³µ ì²´í¬ (ì˜¤ëŠ˜ë§Œ)
                existing = db.query(NewsDaily)\
                    .filter(
                        NewsDaily.date == today,
                        NewsDaily.topic_key == topic_key
                    )\
                    .first()
                
                if existing:
                    continue
                
                # 4. ì–¸ë¡ ì‚¬ í™•ì¸
                source_press = extract_press_from_url(url)
                if not source_press or source_press not in PRESS_BREAKING_CONFIG:
                    continue
                
                # 5. ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜
                category = classify_category(title)
                
                # 6. ì†ë³´ íƒœê·¸ í™•ì¸
                is_breaking = check_breaking_tag(title)
                
                # 7. ì €ì¥
                news = NewsDaily(
                    date=today,
                    category=category,
                    title=title,
                    url=url[:200] if url else "",
                    source=source_press,
                    topic_key=topic_key,
                    is_breaking=is_breaking,
                    is_top=False,
                    hot_score=0,
                    keywords=None,
                    sentiment=None,
                )
                
                temp_news_list.append(news)
                saved_count += 1
                
            except Exception as e:
                print(f"  âš ï¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
        
        print(f"  âœ… ì €ì¥: {saved_count}ê°œ")
        total_saved += saved_count
    
    # ì¤‘ë³µ ì œê±°
    print(f"\nğŸ”„ ì¤‘ë³µ ì œê±° ì¤‘...")
    print(f"\nğŸ”„ ì¤‘ë³µ ì œê±° ì¤‘...")
    print(f"  - ìˆ˜ì§‘: {len(temp_news_list)}ê°œ")
    unique_news_list = remove_duplicate_news(temp_news_list)
    print(f"  - ì¤‘ë³µ ì œê±° í›„: {len(unique_news_list)}ê°œ")
    
    # DB ì €ì¥
    for news in unique_news_list:
        # DBì— ì´ë¯¸ ìˆëŠ”ì§€ ì²´í¬
        existing = db.query(NewsDaily).filter(
            NewsDaily.date == today,
            NewsDaily.topic_key == news.topic_key
        ).first()
        
        if not existing:
            db.add(news)
            created.append(news)
    
    # Commit
    try:
        db.commit()
        for n in created:
            db.refresh(n)
    except IntegrityError as e:
        db.rollback()
        print(f"  âŒ DB ì˜¤ë¥˜: {e}")
        created = []
    
    print(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"ğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ:")
    print(f"  - API ìš”ì²­: {len(PRESS_LIST)}íšŒ")
    print(f"  - ë°›ì€ ë‰´ìŠ¤: {total_fetched}ê°œ")
    print(f"  - ì €ì¥ëœ ë‰´ìŠ¤: {total_saved}ê°œ")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
    
    return created



def filter_repeated_person_names(news_list):
    """ê°™ì€ ì¸ë¬¼ ì´ë¦„ 3ê°œ ì´ìƒ â†’ 3ê°œë§Œ ìœ ì§€"""
    from collections import defaultdict
    import re
    
    person_counts = defaultdict(list)
    
    for news in news_list:
        title = news.title
        
        # ì¸ë¬¼ ì´ë¦„ ì¶”ì¶œ
        patterns = [
            r'([ê°€-í£]{2,4})\s+(ì•ˆë³´ì‹¤ì¥|ëŒ€í†µë ¹|ì´ë¦¬|ì¥ê´€|ì‹¤ì¥|ì˜ì›|ëŒ€í‘œ|íšŒì¥)',
            r'\[ì†ë³´\]\s*([ê°€-í£]{2,4})\s+(ì•ˆë³´ì‹¤ì¥|ëŒ€í†µë ¹|ì´ë¦¬|ì¥ê´€)',
        ]
        
        person_name = None
        for pattern in patterns:
            match = re.search(pattern, title)
            if match:
                person_name = match.group(1)
                break
        
        if person_name:
            person_counts[person_name].append(news)
        else:
            person_counts['_no_person'].append(news)
    
    # ê° ì¸ë¬¼ë³„ ìµœëŒ€ 3ê°œ
    filtered = []
    for person, news_items in person_counts.items():
        if person == '_no_person':
            filtered.extend(news_items)
        else:
            filtered.extend(news_items[:3])
    
    return filtered


def collect_breaking_news(db: Session) -> List[NewsDaily]:
    """ì†ë³´ ë¼ì¸ ìˆ˜ì§‘ (100ê°œ) + ì¤‘ë³µ ì œê±°"""
    
    from backend.app.utils.dedup import remove_duplicate_news
    
    today = date.today()
    created = []
    
    print(f"\nâš¡ ì†ë³´ ë¼ì¸ ìˆ˜ì§‘ ì¤‘...")
    
    items = fetch_naver_news_raw(query="ì†ë³´", display=100)
    
    if not items:
        print(f"  âš ï¸ ê²°ê³¼ ì—†ìŒ")
        return []
    
    # 1ë‹¨ê³„: ëª¨ë“  ì†ë³´ë¥¼ NewsDaily ê°ì²´ë¡œ ë³€í™˜ (ì €ì¥ ì „)
    temp_news_list = []
    
    for item in items:
        try:
            raw_title = item.get("title")
            url = item.get("originallink") or item.get("link")
            
            if not raw_title or not url:
                continue
            
            title = raw_title.replace("<b>", "").replace("</b>", "")
            topic_key = build_topic_key(title)
            
            if not topic_key:
                continue
            
            # ì–¸ë¡ ì‚¬ í™•ì¸
            source_press = extract_press_from_url(url)
            if not source_press or source_press not in PRESS_BREAKING_CONFIG:
                continue
            
            # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            category = classify_category(title)
            
            # NewsDaily ê°ì²´ ìƒì„± (ì•„ì§ DBì— ì €ì¥ ì•ˆ í•¨)
            news = NewsDaily(
                date=today,
                category=category,
                title=title,
                url=url[:200] if url else "",
                source=source_press,
                topic_key=topic_key,
                is_breaking=True,
                is_top=False,
                hot_score=0,
                keywords=None,
                sentiment=None,
            )
            
            temp_news_list.append(news)
            
        except Exception as e:
            continue
    
    # 2ë‹¨ê³„: ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±°
    if temp_news_list:
        print(f"  ğŸ“‹ ìˆ˜ì§‘: {len(temp_news_list)}ê°œ")
        unique_news_list = remove_duplicate_news(temp_news_list)
        print(f"  âœ¨ ì¤‘ë³µ ì œê±° í›„: {len(unique_news_list)}ê°œ")
        unique_news_list = filter_repeated_person_names(unique_news_list)
        print(f"  ğŸ¯ ì¸ë¬¼ í•„í„° í›„: {len(unique_news_list)}ê°œ")
    else:
        unique_news_list = []
    
    # 3ë‹¨ê³„: DBì— ì €ì¥ (topic_key ì¤‘ë³µ ì²´í¬)
    saved_count = 0
    
    for news in unique_news_list:
        try:
            # DBì— ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
            existing = db.query(NewsDaily)\
                .filter(
                    NewsDaily.date == today,
                    NewsDaily.topic_key == news.topic_key
                )\
                .first()
            
            if existing:
                continue
            
            db.add(news)
            created.append(news)
            saved_count += 1
            
        except Exception as e:
            continue
    
    try:
        db.commit()
        for n in created:
            db.refresh(n)
    except IntegrityError:
        db.rollback()
        created = []
    
    print(f"  âœ… ì†ë³´ ì €ì¥: {saved_count}ê°œ\n")
    
    return created


def calculate_hot_score(news_id: int, db: Session) -> int:
    """í•« ì ìˆ˜ ê³„ì‚°"""
    
    news = db.query(NewsDaily).get(news_id)
    if not news:
        return 0
    
    score = 0
    today = date.today()
    now = datetime.now()
    
    # 1. ì¤‘ë³µ ì£¼ì œ ê°œìˆ˜ (ìµœëŒ€ 100ì )
    duplicate_count = db.query(NewsDaily)\
        .filter(
            NewsDaily.topic_key == news.topic_key,
            NewsDaily.date == today
        )\
        .count()
    score += duplicate_count * 10
    
    # 2. ë³´ë„ ì–¸ë¡ ì‚¬ ê°œìˆ˜ (ìµœëŒ€ 50ì )
    press_count = db.query(func.count(func.distinct(NewsDaily.source)))\
        .filter(
            NewsDaily.topic_key == news.topic_key,
            NewsDaily.date == today
        )\
        .scalar()
    score += press_count * 5
    
    # 3. ì†ë³´ íƒœê·¸ (30ì )
    if news.is_breaking:
        score += 30
    
    # 4. ìµœì‹ ë„ (ìµœëŒ€ 10ì )
    hours_old = (now - news.created_at).total_seconds() / 3600
    if hours_old < 1:
        score += 10
    elif hours_old < 3:
        score += 5
    elif hours_old < 6:
        score += 2
    
    # 5. ì£¼ìš” ì–¸ë¡ ì‚¬ ë³´ë„ˆìŠ¤ (5ì )
    major_press = ["ì—°í•©ë‰´ìŠ¤", "YTN", "KBS", "SBS", "ë§¤ì¼ê²½ì œ", "í•œêµ­ê²½ì œ"]
    if any(press in news.source for press in major_press):
        score += 5
    
    return score


def update_hot_scores(db: Session):
    """ëª¨ë“  ì˜¤ëŠ˜ ë‰´ìŠ¤ì˜ í•« ì ìˆ˜ ì—…ë°ì´íŠ¸"""
    
    print(f"\nğŸ”¥ í•« ì ìˆ˜ ê³„ì‚° ì¤‘...")
    
    today = date.today()
    news_list = db.query(NewsDaily)\
        .filter(NewsDaily.date == today)\
        .all()
    
    for news in news_list:
        news.hot_score = calculate_hot_score(news.id, db)
    
    db.commit()
    
    print(f"  âœ… {len(news_list)}ê°œ ë‰´ìŠ¤ ì ìˆ˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ\n")


def select_top_news(db: Session, category: str, limit: int = 10) -> List[NewsDaily]:
    """ì¹´í…Œê³ ë¦¬ë³„ TOP ì„ ì •"""
    
    today = date.today()
    
    top_news = db.query(NewsDaily)\
        .filter(
            NewsDaily.date == today,
            NewsDaily.category == category
        )\
        .order_by(
            NewsDaily.hot_score.desc(),
            NewsDaily.created_at.desc()
        )\
        .limit(limit)\
        .all()
    
    # is_top í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
    for news in top_news:
        news.is_top = True
    
    db.commit()
    
    return top_news


def build_daily_rankings(db: Session):
    """ì „ì²´ ë­í‚¹ êµ¬ì„±"""
    
    print(f"\nğŸ† TOP 10 ì„ ì • ì¤‘...")
    
    # 1. í•« ì ìˆ˜ ì—…ë°ì´íŠ¸
    update_hot_scores(db)
    
    # 2. ê° ì¹´í…Œê³ ë¦¬ë³„ TOP 10
    rankings = {}
    for category in ["society", "economy", "culture", "entertainment"]:
        top_news = select_top_news(db, category, limit=10)
        rankings[category] = top_news
        print(f"  âœ… {category}: {len(top_news)}ê°œ")
    
    print(f"  âœ… TOP 10 ì„ ì • ì™„ë£Œ\n")
    
    return rankings


def get_today_summary(db: Session) -> List[NewsDaily]:
    """ì˜¤ëŠ˜ì˜ ìš”ì•½: ê° ì¹´í…Œê³ ë¦¬ TOP 1"""
    
    summary = []
    today = date.today()
    
    for category in ["society", "economy", "culture", "entertainment"]:
        top1 = db.query(NewsDaily)\
            .filter(
                NewsDaily.date == today,
                NewsDaily.category == category
            )\
            .order_by(
                NewsDaily.hot_score.desc(),
                NewsDaily.created_at.desc()
            )\
            .first()
        
        if top1:
            summary.append(top1)
    
    return summary


def build_daily_top5_v3(db: Session):
    """v3 ì „ì²´ í”Œë¡œìš°"""
    
    print(f"\n" + "="*60)
    print(f"  Morning Bot v3.0 - ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
    print(f"="*60)
    
    try:
        # 1. ì–¸ë¡ ì‚¬ë³„ ìˆ˜ì§‘
        collect_by_press(db)
        
        # 2. ì†ë³´ ë¼ì¸ ìˆ˜ì§‘
        collect_breaking_news(db)
        
        # 3. TOP 10 ì„ ì •
        build_daily_rankings(db)
        
        print(f"="*60)
        print(f"  âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print(f"="*60 + "\n")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
